\documentclass[runningheads]{llncs}
\usepackage[T1]{fontenc}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{color}

\begin{document}

\title{Best practices in measuring energy consumption in population-based metaheuristics}
%
\titlerunning{}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{JJ Merelo\inst{1,2}\orcidID{ 0000-0002-1385-9741 } \and Cecilia Merelo-Molina\inst{3}}

%
\authorrunning{Merelo and Merelo}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%

\institute{Department of Computer Engineering, Automatics and Robotics, University of Granada \email{jmerelo@ugr.es}\and
CITIC, UGR, Spain
\and
Zenzorrito, Granada, Spain}

\maketitle              % typeset the header of the contribution
%
\begin{abstract}


\keywords{Green computing  \and Energy profiling \and Metaheuristics \and Software Engineering.}
\end{abstract}

\section{Introduction}

There are several trends that have converged to influence the development and implementation of optimization algorithms in the last years: the end of Moore's law implies that you cannot optimize performance and energy consumption at the same time; sustainable development objectives aim for lowering the carbon footprint of human endeavors, including science, and finally the pervasiveness of machine learning and optimization techniques make the need for {\em greener} implementations more acute, looking to obtain the same results with less energy.

The rest of the paper is organized as follows: the next Section describes the state of the art in the exploration of energy consumption of evolutionary algorithms and other metaheuristics. Section \ref{sec:bna} describes the algorithm and how it has been parametrized for the purpose of this paper. Since there is no fixed methodology for measuring energy consumption, we will show how it was done for this experiment and the trade-offs it implies, together with the results, in Section \ref{sec:results}; these results will be discussed in the last Section \ref{sec:discussion} along with our conclusions.


\section{State of the art}

Our main focus has been on optimizing energy consumption in implementation of metaheuristics; in general, this research thrust shares many features with other optimization and machine learning algorithms. Large language models, for instance, have lately received intensified attention, with papers focused as much on the the optimization part as on the measurement axis \cite{10549890}. This falls within a context where calls for a better knowledge of energy consumption \cite{7155416}, more efficient software and more energy-aware optimizations have been made \cite{fonseca2019manifesto}. At the end of the day, energy-efficient software is better software and, as with any other implementation issue, understanding better how algorithm implementations spend their time and energy will lead to algorithmic insights that will, eventually, lead to better algorithms \cite{merelo2011implementation}.

The main issue, however, is still a lack of sound methodology, or even a set of best practices, for measuring energy consumption for specific algorithm implementations, not to mention specific functions within them. The challenges were already identified in \cite{von2018measuring}: benchmarking methodologies need to be fair, verifiable, usable but, over all, reproducible. \cite{10549890} presents a finer analysis of these problems, emphasizing the accessibility problem, the power-measuring architecture, and finally the bigger issue from the point of view of algorithms: separating the power consumed by the workload from the overhead caused by the rest of the system. Several recommendations for a {\em green} software engineering have been issued \cite{cruz21b}, with an emphasis on reproducibility \cite{song2025reproducible}. This, indeed, might be the biggest issue. \cite{cotta25} shows that time-related, possibly hysteretic effects due to changes in the physical parameters of the hardware platform will affect the measurements taken by as much as 10\%. As a matter of fact, what we want in this kind of optimization is to ensure that energy consumption is measured and eventually lowered in regular lab conditions, so trying to fix physical conditions in different ways is not really an option.

In this paper we will try to contribute to this line of research, looking mainly at improving reproducibility of results, but also at making the measurements of the workload of interest more precise.

\section{A Brave New Algorithm}\label{sec:bna}

Despite the scathing sentence by SÃ¶rensen \cite{sorensen} that most biologically inspired metaheuristics "take the field of metaheuristics a step backward", we can affirm that in the case of the Brave New Algorithm that is inspired on how selection and reproduction happened in novel Brave New World \cite{huxley2022brave}, we are not dealing with biological, but {\em literary} inspiration, so that does not apply. On the other hand, we are fully aware of the disadvantages of proposing a new terminology for a population-based evolutionary algorithm, so we will explain the algorithm used here in terms of the more widely known evolutionary algorithms, from which it basically departs on the reproduction scheme it uses \cite{blickle1996comparison}.

Because, in essence, the Brave New Algorithm \cite{merelo2022brave} (BNA) uses mutation, crossover as {\em genetic} operators and fitness-based selection to find the optimum of a given function, represented as a {\em chromosome}, in this case a vector of real numbers. The original novel intervenes to inspire a a reproduction restriction scheme that is geared towards having a finer control on the exploration/exploitation balance of the algorithm. This scheme distributes the population in different groups called, as in the book, {\em castes} and they have different reproduction methods. After selection creating a reproductive pool using some kind of selection, new members will be generated depending on the caste:
\begin{itemize}
\item The $\alpha$ caste will generate every new generation via mutation and crossover.
\item The $\beta$ caste will pair one member of the $\alpha$ with one of them and generate new members via mutation and crossover.
\item $\delta$ and $\epsilon$ castes generate new individuals by mutation of other members of its own caste. The only difference between castes is that mutation rates can be set separately.
\item $\gamma$ generates new members by applying mutation repeatedly until a better individual is found.
\end{itemize}

All the new individuals of the population are ranked after being generated and assigned to a caste according to the percentage that has been assigned to every one of them; the $\alpha$ caste will hold the best $\%\alpha$ of the population, and so on.

The parametrization of the algorithm operators is as follows:\begin{itemize}
\item Mutation is applied every time a new individual is generated and changes 40\% of the chromosome elements. Since we are using low dimensions (3,5), this means that one or two elements will be generated randomly at most.
\item We use a two-point crossover.
\item The reproductive pool is created via binary tournament selection.
\end{itemize}

These are mainstream choices in evolutionary algorithms; for the time being our focus is on the energy measuring methodology as well as optimizing the performance of the framework.

Castes are, however, the main differentiation feature of this algorithm, with the percentage allotted to every caste being our main control parameter; these have some restrictions in, due to the way new members are generated: the beta caste needs to have twice as many members as the alpha caste \cite{bna25}. This is why we will use the percentage of population in the $\alpha$ caste as the main lever,as it can be used to generate the rest if we keep $\%\delta$ and $\%\epsilon$ fixed to a low value. In practice, then, after setting $\%\alpha$, we will set $\%\beta = 2 * \%\alpha$ and $\%\gamma = 100\% - (\%\alpha + \%\beta + \%\delta + \%\epsilon)$.

The implementation of the algorithm, as well as all the parameters used, are available under a free license at \url{https://github.com/cecimerelo/BraveNewAlgorithm.jl}

\section{Experimental methodology and results}\label{sec:results}

In order to carry out these experiments, we have used a methodology that is like that used in our previous papers: \cite{low-level-anon}. We employ {\sf pinpoint}, \cite{pinpoint}, a command line tool that taps the RAPL interface \cite{rapl} to measure energy consumption of a given process. The version we have used was compiled from commit {\tt dfee658}. We carry experiments in an AMD Ryzen 9 9950X 16-Core Processor, with Ubuntu Linux 25.04 with kernel version 6.14.0-37-generic. Julia version has been $1.11.7$.\footnote{Julia has now changed the minor version to 1.12, with $1.12.1$ being the latest released at the moment of writing this paper. However, there are some performance issues with this new version, which has prevented us for using it for the time being.}

We have used the Sphere function \cite{hansen2010comparing}, defined as sum of the squares of the distance to the center minus a fixed value, which is part of the BBOB benchmarks; as a matter of fact, the implementation of this function is taken from the {\sf BlackBoxOptimizationBenchmarking.jl}, also written in Julia. This function is also lightweight enough to allow us to compare the energy profiles of different combinations of genetic operators, which will then have a bigger impact on overall consumption.

We have first tried to follow the best practices in sampling. We were previously using the default value of 50ms. In general, it is advised to increase the sampling period to avoid errors in the estimation, so we have doubled it to 100ms.

<<ola.base.frequency, echo=FALSE, warning=F, message=F>>=
null_baseline_columns <- c("alpha", "max_gens", "different_seeds", "diff_fitness", "generations", "evaluations")
baseline_data_evoapps <- read.csv("data/evoapps-1.11.7-baseline-bna-baseline-16-Oct-11-08-20.csv")
baseline_data_evoapps[ null_baseline_columns ] <- NULL

baseline_data_ola_100s <- read.csv( "data/ola-base-ola-baseline-14-Dec-12-06-42.csv")
baseline_data_ola_100s$work <- "ola-baseline"
baseline_data_ola_100s[null_baseline_columns] <- NULL

initial_baseline_data <- rbind(baseline_data_evoapps, baseline_data_ola_100s)
initial_baseline_data$power <- initial_baseline_data$PKG / initial_baseline_data$seconds
library(ggplot2)
#ggplot(initial_baseline_data,aes(x=PKG,y=seconds,color=work))+geom_point() + theme_minimal() +
  # xlab("Package energy (Joules)") +
  # ylab("Time (seconds)")

library(dplyr)
initial_baseline_data %>% group_by(population_size, dimension, work) %>% summarise(
    mean_pkg = mean(PKG),
    sd_pkg = sd(PKG),
    mean_time = mean(seconds),
    sd_time = sd(seconds),
    mean_power = mean(power),
    sd_power = sd(power)
  ) -> initial_baseline_data_summary

# compute wilcoxon tests between work values for every population_size and dimension
wilcoxon_results <- data.frame()
for (pop_size in unique(initial_baseline_data$population_size)) {
  for (dim in unique(initial_baseline_data$dimension)) {
    data_subset <- initial_baseline_data %>% filter(population_size == pop_size, dimension == dim)
    work_values <- unique(data_subset$work)
    if (length(work_values) == 2) {
      work1_data <- data_subset %>% filter(work == work_values[1]) %>% pull(power)
      work2_data <- data_subset %>% filter(work == work_values[2]) %>% pull(power)
      wilcox_test <- wilcox.test(work1_data, work2_data)
      wilcoxon_results <- rbind(wilcoxon_results, data.frame(
        population_size = pop_size,
        dimension = dim,
        work1 = work_values[1],
        work2 = work_values[2],
        p_value = wilcox_test$p.value
      ))
    }
  }
}

initial_baseline_data_summary$sd_and_mean_pkg <- paste0("$",
  round(initial_baseline_data_summary$mean_pkg, 2), " \\pm", round(initial_baseline_data_summary$sd_pkg, 2), "$"
)

library(reshape2)
initial_baseline_table <- reshape2::dcast(
  initial_baseline_data_summary,
  population_size + dimension ~ work,
  value.var = "sd_and_mean_pkg"
)

library(kableExtra)

kable(initial_baseline_table, "latex",
      col.names = c("Population size","Chromosome dimension","Baseline PKG (J)","Sampling = 100s"),
      caption = "Baseline energy consumption for different sampling frequencies",
      escape=FALSE) %>%
  kable_styling( full_width = F)

@

Results for measurement of baseline runs (which generate the initial population) are shown in Table \ref{tab:ola.base.frequency}.

<<ola.deltas, echo=FALSE, warning=F, message=F,fig.cap="Workload energy spent vs. time for the initial configuration vs. measurements with sampling period = 100 ms", fig.height=3>>=
compute_deltas <- function( baseline_summary, workload ) {
  workload$delta_PKG <-0
  workload$delta_seconds <- 0
  for (dim in c(3,5)) {
    for ( pop_size in c(200,400)) {
      number_of_rows <- nrow(workload[ workload$dimension==dim & workload$population_size==pop_size,])
      workload[ workload$dimension==dim & workload$population_size==pop_size,]$delta_PKG <-
      workload[ workload$dimension==dim & workload$population_size==pop_size,]$PKG  -
      rep(baseline_summary[ baseline_summary$population_size == pop_size & baseline_summary$dimension==dim, ]$median_energy,number_of_rows)

      workload[ workload$dimension==dim & workload$population_size==pop_size,]$delta_seconds <-
      workload[ workload$dimension==dim & workload$population_size==pop_size,]$seconds  -
      rep(baseline_summary[ baseline_summary$population_size == pop_size & baseline_summary$dimension==dim, ]$median_time,number_of_rows)
    }
  }
  return (workload)
}

baseline_data_evoapps %>% group_by(dimension,population_size) %>%
  summarise(median_energy=median(PKG), sd_energy=sd(PKG),
            trimmed_mean_energy=mean(PKG,trim=0.2),
            median_time=median(seconds), sd_time=sd(seconds),
            trimmed_mean_time=mean(seconds, trim=0.2)) -> summary_baseline_data_evoapps

workload_data_evoapps <- read.csv("data/evoapps-1.11.7-fix-rand-bna-fix-rand-25-Oct-11-06-07.csv")
workload_data_evoapps <- compute_deltas( summary_baseline_data_evoapps, workload_data_evoapps )

workload_data_evoapps %>% group_by(dimension,population_size,max_gens,alpha) %>%
  summarise(median_delta_energy=median(delta_PKG), sd_delta_energy=sd(delta_PKG),
            trimmed_mean_delta_energy=mean(delta_PKG,trim=0.2),
            median_delta_time=median(delta_seconds), sd_delta_time=sd(delta_seconds),
            trimmed_mean_delta_time=mean(delta_seconds, trim=0.2)) -> summary_workload_data_evoapps

baseline_data_ola_100s %>% group_by(dimension,population_size) %>%
  summarise(median_energy=median(PKG), sd_energy=sd(PKG),
            trimmed_mean_energy=mean(PKG,trim=0.2),
            median_time=median(seconds), sd_time=sd(seconds),
            trimmed_mean_time=mean(seconds, trim=0.2)) -> summary_baseline_data_ola

workload_data_ola <- read.csv("data/ola-1.11.7-ola-14-Dec-13-02-30.csv")
workload_data_ola <- compute_deltas( summary_baseline_data_ola, workload_data_ola )

workload_data <- rbind( workload_data_evoapps, workload_data_ola )

ggplot(workload_data, aes(x=delta_seconds, y=delta_PKG, color=as.factor(work))) +
  geom_point() +
  theme_minimal() +
  xlab("Delta Time (seconds)") +
  ylab("Delta Package energy (Joules)") +
  labs(color="Measurement frequency")
@

In Figure \ref{fig:ola.deltas} we show the differential of energy spent vs. the time needed with the new sampling frequency (once ever 100ms) vs. the old one (50ms). What is interesting to see here is that just a change in the measuring tool configuration leads to significant changes in the distribution as well as the absolute values of energy consumed and time spent. However, time spent should not, a priori, be affected by the measuring tool, so what we see here is that we have only reduced a source of uncertainty, error in measurement, not every one of them. We still have the issue of very small values, below 50 Joules, that are not realistic, over all for time measurements that are below one second. This will be addressed later.



\section{Conclusion and discussion}
\label{sec:discussion}



\section*{Acknowledgements}
This work is supported by the Ministerio espa\~{n}ol de Econom\'{\i}a y Competitividad (Spanish Ministry of Competitivity and Economy) under project PID2023-147409NB-C21.

\bibliographystyle{splncs04}
\bibliography{ours,energy,ga-energy,GAs,julia,metaheuristics}

\end{document}
